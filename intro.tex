\section{Introduction}\label{sec:intro}

\aanote[margin, noinline]{update abstract?}

Machine learning systems must be able to represent and reason about relations between objects, either explicitly or implicitly. For example, a natural language understanding system takes a sequence of words as input and extracts information about the meaning of the words based on relations between them in the local context. Similarly, a scene analysis system considers the relations between the components of a scene in order to identify and interpret the objects.

A common way to represent relations between objects is through inner products between feature representations of the form $\iprod{\phi(x)}{\psi(y)}$, where $x, y \in \calX$ are two objects and $\phi, \psi$ are neural network feature maps. Inner products posses properties which make them useful measures of similarity. The aim of this paper is to understand the representational power of this model by characterizing the class of relation functions $r: \calX \times \calX \to \reals$ which can be represented as inner products of neural networks.

The use of inner products between feature maps is widespread in machine learning architectures. A notable example is the attention mechanisms that lie at the heart of sequence models like the Transformer~\parencite{vaswani2017attention}. In the Transformer, self-attention is implemented as
\begin{equation*}
    \begin{split}
        \alpha_{ij} &\gets \mathrm{Softmax}\paren{\bra{{\iprod{\phi_q(x_i)}{\phi_k(x_j)}}}_{j \in [n]}}_j\\
        x_i' &\gets \sum_{j=1}^{n} \alpha_{ij} \phi_v(x_j)
    \end{split}
\end{equation*}
where $\phi_q, \phi_k$, and $\phi_v$ are learned transformations and $\iprod{\phi_q(x_i)}{\phi_k(x_j)}$ represents a relation between $x_i$ and $x_j$, which determines how much $i$ should attend to $j$. A similar mechanism is at play in earlier neural architectures which implement a content-addressable external memory~\parencite{gravesNeuralTuringMachines2014,gravesHybridComputingUsing2016a,pritzelNeuralEpisodicControl2017}, wherein the read/write operations are typically implememnted using an inner product-based similarity computation followed by a softmax-normalization. Since the Transformer, attention has also been used in other architectures to model relations between different entities~\parencite{velickovicGraphAttentionNetworks2017a,santoroRelationalRecurrentNeural2018,zambaldiDeepReinforcementLearning2018a,locatelloObjectCentricLearningSlot2020b}. For example, \citet{santoroRelationalRecurrentNeural2018} propose a recurrent neural network with a memory module which employs dot product attention to allow memories to interact and model relations within the memory.

The Transformer models relations implicitly through its attention mechanism. Modeling relations through inner products of features is also central to many ``explicitly relational'' neural architectures~\parencite[e.g.,][]{webbEmergentSymbols2021,kergNeuralArchitecture2022,altabaaAbstractorsTransformer2023,altabaaRelationalConvolutionalNetworks2023}. For example, in the model proposed by~\cite{kergNeuralArchitecture2022}, a similarity matrix is computed consisting of symmetric inner products between each pair of objects, $R_{i,\cdot} = \mathrm{Softmax}\pparen{\bra{\iprod{\phi(x_i)}{\phi(x_j)}}_{j\in[n]}}$.~\cite{altabaaAbstractorsTransformer2023} propose a Transformer-based architecture imbued with relational inductive biases by replacing the values $\phi_v(x_i)$ with vector representations which identify objects but are independent of object-level features.~\cite{altabaaRelationalConvolutionalNetworks2023} propose a relational architecture where the central operation is a type of ``convolution'' operating on a tensor of relations computed via inner products of feature maps.

Siamese networks~\parencite{rumelhartLearningRepresentationsBackpropagating1986,langTimedelayNeuralNetwork1988,bromleySignatureVerificationUsing1993,baldiNeuralNetworksFingerprint1993,chopraLearningSimilarityMetric2005,kochSiameseNeuralNetworks2015} are another domain where understanding the function classes of inner products of neural network transformations is relevant. Siamese networks consist of two identical copies of a neural network, with shared parameters, which process two inputs independently producing feature vectors which are then compared using some distance metric to determine the similarity or dissimilarity between the inputs. If the distance is the Euclidean distance, then $\twonorm{\phi(x) - \phi(y)}^2 = \iprod{\phi(x)}{\phi(x)} + \iprod{\phi(y)}{\phi(y)} - 2 \iprod{\phi(x)}{\phi(y)}$, where again the inner product of neural networks arises.

\aanote[margin, noinline]{add brief overview of universal approximation results for MLPs? Mention classical references such as Barron, Cybenko, etc., and more recent analysis such as Bach, etc.?}
% universal approximation of feedforward neural networks has been extensively studied (e.g., classical references are ... Barron, Cybenko, etc.)


In this paper we characterize the function class of inner products of neural networks, showing that inner products of neural networks are universal approximators for relation functions. In particular, when the inner product of neural networks is symmetric (i.e., $\phi=\psi$), the function class is the class of continuous positive definite kernels. When the inner product is asymmetric (i.e., $\phi \neq \psi$), the function class is all continuous bivariate functions on $\calX \times \calX$. The symmetric case is related to kernels of reproducing kernel Hilbert spaces whereas the asymmetric case admits a connection to kernels of reproducing kernel Banach spaces. We apply these results to analyzing the attention operation, showing that any retrieval function described by arbitrary pre-order define 