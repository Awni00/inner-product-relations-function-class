@online{altabaaAbstractorsTransformer2023,
  title = {Abstractors: {{Transformer Modules}} for {{Symbolic Message Passing}} and {{Relational Reasoning}}},
  shorttitle = {Abstractors},
  author = {Altabaa, Awni and Webb, Taylor and Cohen, Jonathan and Lafferty, John},
  date = {2023-04-01},
  url = {https://arxiv.org/abs/2304.00195v2},
  urldate = {2023-06-28},
  langid = {english},
  pubstate = {preprint}
}

@article{barronUniversalApproximation1993,
  title = {Universal Approximation Bounds for Superpositions of a Sigmoidal Function},
  author = {Barron, A.R.},
  date = {1993-05},
  journaltitle = {IEEE Transactions on Information Theory},
  shortjournal = {IEEE Trans. Inform. Theory},
  volume = {39},
  number = {3},
  pages = {930--945},
  issn = {0018-9448, 1557-9654},
  doi = {10.1109/18.256500},
  url = {https://ieeexplore.ieee.org/document/256500/},
  urldate = {2023-03-31}
}

@article{cybenkoApproximationSuperpositions1989,
  title = {Approximation by Superpositions of a Sigmoidal Function},
  author = {Cybenko, G.},
  date = {1989-12},
  journaltitle = {Mathematics of Control, Signals, and Systems},
  shortjournal = {Math. Control Signal Systems},
  volume = {2},
  number = {4},
  pages = {303--314},
  issn = {0932-4194, 1435-568X},
  doi = {10.1007/BF02551274},
  url = {http://link.springer.com/10.1007/BF02551274},
  urldate = {2023-03-31},
  langid = {english}
}

@online{devitoExtensionMercer2011,
  title = {An Extension of {{Mercer}} Theorem to Vector-Valued Measurable Kernels},
  author = {De Vito, Ernesto and Umanita`, Veronica and Villa, Silvia},
  date = {2011-10-18},
  eprint = {1110.4017},
  eprinttype = {arxiv},
  eprintclass = {math},
  url = {http://arxiv.org/abs/1110.4017},
  urldate = {2023-05-06},
  pubstate = {preprint}
}

@article{hornikMultilayerFeedforward1989,
  title = {Multilayer Feedforward Networks Are Universal Approximators},
  author = {Hornik, Kurt and Stinchcombe, Maxwell and White, Halbert},
  date = {1989-01-01},
  journaltitle = {Neural Networks},
  shortjournal = {Neural Networks},
  volume = {2},
  number = {5},
  pages = {359--366},
  issn = {0893-6080},
  doi = {10.1016/0893-6080(89)90020-8},
  url = {https://www.sciencedirect.com/science/article/pii/0893608089900208},
  urldate = {2022-10-07},
  langid = {english}
}

@article{Kerg2022OnNA,
  title={On Neural Architecture Inductive Biases for Relational Tasks},
  author={Giancarlo Kerg and Sarthak Mittal and David Rolnick and Yoshua Bengio and Blake Aaron Richards and Guillaume Lajoie},
  journal={ArXiv},
  year={2022},
  volume={abs/2206.05056},
  url={https://api.semanticscholar.org/CorpusID:249605514}
}

@online{kergNeuralArchitecture2022,
  title = {On {{Neural Architecture Inductive Biases}} for {{Relational Tasks}}},
  author = {Kerg, Giancarlo and Mittal, Sarthak and Rolnick, David and Bengio, Yoshua and Richards, Blake and Lajoie, Guillaume},
  date = {2022-06-09},
  eprint = {2206.05056},
  eprinttype = {arxiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2206.05056},
  url = {http://arxiv.org/abs/2206.05056},
  urldate = {2022-09-13},
  pubstate = {preprint}
}

@article{mercerFunctionsPositive1909,
  title = {Functions of {{Positive}} and {{Negative Type}}, and Their {{Connection}} with the {{Theory}} of {{Integral Equations}}},
  author = {Mercer, J.},
  date = {1909},
  journaltitle = {Philosophical Transactions of the Royal Society of London. Series A},
  volume = {209},
  eprint = {91043},
  eprinttype = {jstor},
  pages = {415--446},
  publisher = {{The Royal Society}},
  issn = {0264-3952},
  url = {https://www.jstor.org/stable/91043},
  urldate = {2023-03-31}
}

@article{micchelliUniversalKernels2006,
  title = {Universal {{Kernels}}},
  author = {Micchelli, Charles A. and Xu, Yuesheng and Zhang, Haizhang},
  date = {2006},
  journaltitle = {Journal of Machine Learning Research},
  volume = {7},
  number = {95},
  pages = {2651--2667},
  issn = {1533-7928},
  url = {http://jmlr.org/papers/v7/micchelli06a.html},
  urldate = {2023-03-31}
}

@inproceedings{santoroRelationalRecurrent2018,
  title = {Relational Recurrent Neural Networks},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  author = {Santoro, Adam and Faulkner, Ryan and Raposo, David and Rae, Jack and Chrzanowski, Mike and Weber, Theophane and Wierstra, Daan and Vinyals, Oriol and Pascanu, Razvan and Lillicrap, Timothy},
  date = {2018},
  volume = {31},
  publisher = {{Curran Associates, Inc.}},
  url = {https://proceedings.neurips.cc/paper/2018/hash/e2eabaf96372e20a9e3d4b5f83723a61-Abstract.html},
  urldate = {2022-11-11}
}

@online{santoroSimpleNeural2017,
  title = {A Simple Neural Network Module for Relational Reasoning},
  author = {Santoro, Adam and Raposo, David and Barrett, David G. T. and Malinowski, Mateusz and Pascanu, Razvan and Battaglia, Peter and Lillicrap, Timothy},
  date = {2017-06-05},
  eprint = {1706.01427},
  eprinttype = {arxiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/1706.01427},
  urldate = {2022-11-11},
  pubstate = {preprint}
}

@article{seelyNonSymmetricKernels1919,
  title = {Non-{{Symmetric Kernels}} of {{Positive Type}}},
  author = {Seely, Dr. Caroline E.},
  date = {1919-03},
  journaltitle = {The Annals of Mathematics},
  shortjournal = {The Annals of Mathematics},
  volume = {20},
  number = {3},
  eprint = {1967866},
  eprinttype = {jstor},
  pages = {172--176},
  issn = {0003486X},
  doi = {10.2307/1967866},
  url = {https://www.jstor.org/stable/1967866?origin=crossref},
  urldate = {2023-04-13}
}

@article{sunMercerTheorem2005,
  title = {Mercer Theorem for {{RKHS}} on Noncompact Sets},
  author = {Sun, Hongwei},
  date = {2005-06},
  journaltitle = {Journal of Complexity},
  shortjournal = {Journal of Complexity},
  volume = {21},
  number = {3},
  pages = {337--349},
  issn = {0885064X},
  doi = {10.1016/j.jco.2004.09.002},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0885064X04000822},
  urldate = {2023-03-31},
  langid = {english}
}

@article{aronszajn1950theory,
  title={Theory of reproducing kernels},
  author={Aronszajn, Nachman},
  journal={Transactions of the American mathematical society},
  volume={68},
  number={3},
  pages={337--404},
  year={1950}
}

@online{webbEmergentSymbols2021,
  title = {Emergent {{Symbols}} through {{Binding}} in {{External Memory}}},
  author = {Webb, Taylor W. and Sinha, Ishan and Cohen, Jonathan D.},
  date = {2021-03-09},
  eprint = {2012.14601},
  eprinttype = {arxiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2012.14601},
  url = {http://arxiv.org/abs/2012.14601},
  urldate = {2022-09-13},
  pubstate = {preprint}
}

@inproceedings{zhangReproducingKernel2009,
  title = {Reproducing Kernel {{Banach}} Spaces for Machine Learning},
  booktitle = {2009 {{International Joint Conference}} on {{Neural Networks}}},
  author = {Zhang, Haizhang and Xu, Yuesheng and Zhang, Jun},
  date = {2009-06},
  pages = {3520--3527},
  publisher = {{IEEE}},
  location = {{Atlanta, Ga, USA}},
  doi = {10.1109/IJCNN.2009.5179093},
  url = {http://ieeexplore.ieee.org/document/5179093/},
  urldate = {2023-05-06},
  eventtitle = {2009 {{International Joint Conference}} on {{Neural Networks}} ({{IJCNN}} 2009 - {{Atlanta}})},
  isbn = {978-1-4244-3548-7},
  langid = {english}
}

@inproceedings{chopraLearningSimilarityMetric2005,
  author={Chopra, S. and Hadsell, R. and LeCun, Y.},
  booktitle={2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'05)}, 
  title={Learning a similarity metric discriminatively, with application to face verification}, 
  year={2005},
  pages={539-546},
  doi={10.1109/CVPR.2005.202}}

@article{seelyNonSymmetricKernelsPositive1919,
  title = {Non-{{Symmetric Kernels}} of {{Positive Type}}},
  author = {Seely, Dr. Caroline E.},
  year = {1919},
  month = mar,
  journal = {The Annals of Mathematics},
  volume = {20},
  number = {3},
  eprint = {1967866},
  eprinttype = {jstor},
  pages = {172},
  issn = {0003486X},
  doi = {10.2307/1967866},
  urldate = {2023-04-13}
}

@article{vaswani2017attention,
  title={Attention is all you need},
  author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}

@misc{mhaskarDeepVsShallow2016,
  title = {Deep vs. Shallow Networks : {{An}} Approximation Theory Perspective},
  shorttitle = {Deep vs. Shallow Networks},
  author = {Mhaskar, Hrushikesh and Poggio, Tomaso},
  year = {2016},
  month = aug,
  journal = {arXiv.org},
  urldate = {2024-01-03},
  abstract = {The paper briefy reviews several recent results on hierarchical architectures for learning from examples, that may formally explain the conditions under which Deep Convolutional Neural Networks perform much better in function approximation problems than shallow, one-hidden layer architectures. The paper announces new results for a non-smooth activation function - the ReLU function - used in present-day neural networks, as well as for the Gaussian networks. We propose a new definition of relative dimension to encapsulate different notions of sparsity of a function class that can possibly be exploited by deep networks but not by shallow ones to drastically reduce the complexity required for approximation and learning.},
  howpublished = {https://arxiv.org/abs/1608.03287v1},
  langid = {english}
}

@misc{okunoProbabilisticFrameworkMultiview2018,
  title = {A Probabilistic Framework for Multi-View Feature Learning with Many-to-Many Associations via Neural Networks},
  author = {Okuno, Akifumi and Hada, Tetsuya and Shimodaira, Hidetoshi},
  year = {2018},
  month = jun,
  number = {arXiv:1802.04630},
  eprint = {1802.04630},
  primaryclass = {stat},
  publisher = {{arXiv}},
  urldate = {2024-01-01},
  abstract = {A simple framework Probabilistic Multi-view Graph Embedding (PMvGE) is proposed for multi-view feature learning with many-to-many associations so that it generalizes various existing multi-view methods. PMvGE is a probabilistic model for predicting new associations via graph embedding of the nodes of data vectors with links of their associations. Multi-view data vectors with many-to-many associations are transformed by neural networks to feature vectors in a shared space, and the probability of new association between two data vectors is modeled by the inner product of their feature vectors. While existing multi-view feature learning techniques can treat only either of many-to-many association or non-linear transformation, PMvGE can treat both simultaneously. By combining Mercer's theorem and the universal approximation theorem, we prove that PMvGE learns a wide class of similarity measures across views. Our likelihood-based estimator enables efficient computation of non-linear transformations of data vectors in large-scale datasets by minibatch SGD, and numerical experiments illustrate that PMvGE outperforms existing multi-view methods.},
  archiveprefix = {arxiv}
}

@article{poggioWhyWhenCan2017,
  title = {Why and When Can Deep-but Not Shallow-Networks Avoid the Curse of Dimensionality: {{A}} Review},
  shorttitle = {Why and When Can Deep-but Not Shallow-Networks Avoid the Curse of Dimensionality},
  author = {Poggio, Tomaso and Mhaskar, Hrushikesh and Rosasco, Lorenzo and Miranda, Brando and Liao, Qianli},
  year = {2017},
  month = oct,
  journal = {International Journal of Automation and Computing},
  volume = {14},
  number = {5},
  pages = {503--519},
  issn = {1476-8186, 1751-8520},
  doi = {10.1007/s11633-017-1054-2},
  urldate = {2024-01-03},
  abstract = {The paper characterizes classes of functions for which deep learning can be exponentially better than shallow learning. Deep convolutional networks are a special case of these conditions, though weight sharing is not the main reason for their exponential advantage.},
  langid = {english}
}